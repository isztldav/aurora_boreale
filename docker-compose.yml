services:
  db:
    image: postgres:15
    container_name: dashboard-db
    environment:
      POSTGRES_USER: dashboard
      POSTGRES_PASSWORD: dashboard
      POSTGRES_DB: dashboard
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - internal

  web:
    build:
      context: .
      dockerfile: src/dashboard/Dockerfile
    container_name: dashboard-web
    working_dir: /app
    # Mount the app source and a shared logs volume (TensorBoard runs)
    volumes:
      - ./:/app
      - shared_logs:/app/runs
    environment:
      # Point the app to Postgres in the internal network
      DASHBOARD_DB_URL: postgresql+psycopg2://dashboard:dashboard@db:5432/dashboard
      # Optional: tune TensorBoard mount lifecycle in the web app
      TB_IDLE_TIMEOUT: "600"       # seconds
      TB_SWEEP_INTERVAL: "30"      # seconds
      PYTHONUNBUFFERED: "1"
      PYTHONPATH: /app/src
    command: bash -lc "python run_dashboard.py"
    depends_on:
      db:
        condition: service_healthy
    ports:
      - "8000:8000"
    networks:
      - internal

  agent:
    # Build an image that pre-installs heavy CUDA/PyTorch deps
    build:
      context: .
      dockerfile: src/agent/Dockerfile
    container_name: training-agent
    working_dir: /app
    # Mount the app source and the same shared logs volume for writing TB logs
    volumes:
      - ./:/app
      - shared_logs:/app/runs
      # Host datasets folder mounted inside the agent container
      - ./datasets:/app/datasets
    environment:
      DASHBOARD_DB_URL: postgresql+psycopg2://dashboard:dashboard@db:5432/dashboard
      NVIDIA_VISIBLE_DEVICES: all
      PYTHONUNBUFFERED: "1"
      # Where datasets are mounted inside the container
      DATASETS_DIR: /app/datasets
      # GPU index this container will serve (one agent per GPU)
      GPU_INDEX: "0"
      PYTHONPATH: /app/src
    # Run the agent directly; deps are already installed in the image
    command: bash -lc "python -m agent.server --gpu-index $$GPU_INDEX"
    # Increase shared memory for PyTorch DataLoader workers
    shm_size: "2gb"
    depends_on:
      db:
        condition: service_healthy
    # Request all GPUs from the host (Compose v2+)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
#              count: 1
              device_ids: ["${GPU_INDEX:-0}"]
              capabilities: [gpu]
    networks:
      - internal

networks:
  internal:
    driver: bridge

volumes:
  pgdata:
  shared_logs:
